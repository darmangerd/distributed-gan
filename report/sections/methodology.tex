\chapter{Methodology}
\label{chap:methodology}
To answer our scientific questions, we employed the architecture and algorithm proposed by the MD-GAN paper \cite{mdgan}. Other architectures, such as the one described in \cite{fedgan}, have each worker holding a generator and a discriminator, training both during the learning phase, and periodically synchronizing them to train a global generator. The advantage of the MD-GAN architecture is that it scales up GAN training while maintaining a relatively small memory footprint and using fewer computational resources per worker. In contrast, FedGAN requires each worker to hold and train an additional generator, increasing the resource requirements. We evaluated that the most relevant existing solution to answer our scientific question will therefore be the MD-GAN. 

\section{Distributed architectures}
The proposed architecture consists of a single server holding a generator model and $N$ workers, each with their own discriminator. At the beginning of each epoch, the server sends generated images, based on the current generator, to each worker. Each worker then uses a batch of their own real images and the received data to perform $L$ local epochs. The model is evaluated on a portion of the images sent by the server at the beginning of the epoch, generating gradients (feedback) to send back to the server. Periodically, the discriminators are swapped among workers to prevent overfitting to local data without sharing any data with other workers or the server.
\figureWithCaption{mdgan}{The Multi-Discriminator GANs architecture proposed by \cite{mdgan}}{\textwidth}

\section{MD-GAN Algorithm}
Whenever the server starts one epoch its send the generated $k$ batches to the corresponding clients using the optimal $K=\log(N)$ (with $N$ the number of workers) value determined by \cite{mdgan}. Each of these $k$ batches of data contains two batches of fake images generated by the current version of the generator.

More formally, the server will generate $k$ batches $K = \{X^{(0)}, \dots, X^{(k)}\}$ at the beginning of every epoch, and every worker $n$ will receive the batches $X^{(g)} := X^{(n \mod k)}$ and $X^{(d)} := X^{((n+1) \mod k)}$.

Once the client received $X^{(g)}$ and $X^{(d)}$ it will perform $L$ learning step on $X^{(d)}$ and batch of real images they own. In our experiments $L$ is set to 1, mimicking the standard way of training a GAN in a standalone setting. After the learning iterations finished it will evaluate the loss function on $X^{(g)}$, the gradients (so called feedbacks) of that evaluation will be send to the server for aggregation.

As soon as the server received all the gradients which corresponds to the error made by the Generator on every $X^{(g)}$. The server will aggregate all the gradients as describe in \cite{mdgan} and perform an optimization step. To perform this aggregation we use \code{torch.autograd.grad}\footnote{\url{https://pytorch.org/docs/stable/generated/torch.autograd.grad.html\#torch-autograd-grad}} to calculate the partial derivatives of every element of $X^{(g)}$ with respect to all the weights of the current version of the generator (with the feedbacks as the vector in the vector-Jacobian product).

From this algorithm is it very easy to infer the message count per epoch. At every epoch the server will send two batches of image, both of size $b$, to every worker $\rightarrow N$ messages are sent by the server of size. Therefore, each workers receive 1 message from the server, after training they all send back their feedbacks in one single message, summing up back to $N$ message for the server to receive. This process is repeated at every epoch.

\section{Client swapping}
The most challenging part is the client swapping, we choosed a different strategy than the one proposed by MD-GAN \cite{mdgan}. Although their method work, we estimated that it wasn't optimal for many reason:
\begin{enumerate}
    \item When workers chooses another worker to swap with conflicts can occur, inducing a non-optimal swapping of the workers, for instance worker 1 could decide to swap with worker 2 which decide to swap with worker 1, creating a loop. This would induces to send two times the size of the discriminator for no benefits because worker 1 would end up with its initial weights as well as for worker 2.
    \item Workers might not be considered for swapping which might not help in preventing over-fitting.
    \item Detecting these conflicts in a interaction graph would not be optimal because, because there is no central entity that could detect them.
    \item A $N-1$ separate threads have to be created to handle whenever one of the other workers wants to swap with the current worker. Because of the fact that they could swap at different moments. These threads holds a infinite loop waiting for an answer for another worker, which might never happen. This create dangling TCP connections which introduce instability in the code, for instance a receive timeout could be reached and throw an error, which stops our program.
    \item There swap formula depends on other factor such as the number of local epochs, the size of the real images dataset every worker hold and the batch size. First, this makes the result transcription more complicated because it varies from dataset to others. For simplicity and to transcript our results in a more transparent way we choosed to set the swapping frequency (\code{swap\_interval}) constant. Secondly the size of the batch every worker hold could vary, making the swap not synchronous and enforcing us to use separate threads.
    \item Using separate threads would enforce us to use the \code{tag} argument in \code{dist.send} and \code{dist.recv} which isn't supported on the NCCL backend\footnote{\url{https://pytorch.org/docs/stable/distributed.html\#torch.distributed.isend}}, therefore we would be forced to use the GLOO backend and transmit all the tensors from the GPU to the CPU whenever we want to communicate with another node, inducing more delay.
\end{enumerate}

For all these reasons we introduced a novel swapping strategy that allows for using the NCCL backend. Instead of letting every worker decide with which other worker they should swap with, the server will generate pairs non-overlapping pairs (solve the 1st and 2nd and 3rd problem) of workers and it sends to every worker the rank of the other worker they will swap with. By non-overlapping pair we mean that a worker rank will never appear in more than one pair, for instance $\{(1, 2), (3, 4)\}$ aren't overlapping but $\{(1, 2), (2, 4)\}$ are, this will naturally prevent the 2nd problem from occurring. The swapping operation will be triggered at the same epoch for every node at a frequency defined by the \code{swap\_interval} parameter, solving the 4th, 5th and 6th problems. The only constraint this induce is to have a even number of worker (\code{world\_size} must be odd because it takes into account the server) so every worker can find a partner to swap with.

A message count analysis can be done very easily from that method:
\begin{enumerate}
    \item Every time a swap is triggered we introduce $N$ messages to send containing once integer (4 bytes)\\
    Message count: $N$, bytes sent over the network: $4N$
    \item Every worker will send the model to another worker and receive back another model, considering the size of the model being $W$.
    Message count: $N$, bytes sent over the network: $WN$
\end{enumerate}
At every swapping event $2N$ messages will transit over the network with a total size in byte of $N(4+W)$. In the MD-GAN implementation whenever all the workers has been swapped, $N$ messages count occurred because every worker sent their weights directly to another worker, without any other communication, with a total size of $NW$ bytes. Our method has a bigger network overhead in terms of swapping but solves numerous problems and allow for not transmitting tensor from the CPU to the GPU and vis-versa. Additionally the cost of this operation is amortized by the fact that it occurs at relatively big intervals, therefore we believe that this is not a problematic trade-off.

The pseudo-code of the whole training phase is given in the appendix \ref{appendix:algo}.

\begin{table}[ht]
\centering
\begin{tabular}{|
>{\columncolor[HTML]{EFEFEF}}l |l|l|}
\hline
 & \cellcolor[HTML]{EFEFEF}\textbf{Sent} & \cellcolor[HTML]{EFEFEF}\textbf{Received} \\ \hline
\textbf{Server sends generated data (Server to Workers)} & $2bN$ & $2b$ \\ \hline
\textbf{Worker $n$ send feedback (Worker to Server)} & $b$ & $bN$ \\ \hline
\textbf{Server send swap instructions (Server to Workers)} & $N$ & $1$ \\ \hline
\textbf{Worker send discriminator (Worker to Worker)} & $|D|$ & $|D|$ \\ \hline
\end{tabular}
\caption{All the type of communication occurring in our training procedure, the size is the number of individual floating point number sent/received within PyTorch tensors (float64).}
\label{tab:comm}
\end{table}

\section{Evaluation of the results}
Evaluating generative models is challenging. The effectiveness of these models depends on the quality of data they produce, which ideally should be judged by humans. To simulate this human evaluation, researchers have developed automated methods.

We selected the Inception Score (IS) and Fr√©chet Inception Distance (FID) as our primary metrics due to their proven effectiveness in evaluating generative models. Both metrics are commonly use to asses the performances of GANs, enabling us for direct comparison of our results with other GANs' benchmarks. This alignment ensures that our evaluations are relevant and scientifically rigorous, improving the validity of our findings within the broader research context.

\subsection{Inception Score (IS)}
One well-known method is the Inception Score (IS). This score helps assess how good the generated data is by using a pre-trained classifier called the Inception network. The Inception Score looks at two things:
\begin{enumerate}
    \item \textbf{Confidence}: It checks if the Inception network can confidently recognize what the generated data represents.  A higher confidence level indicates that the generated data closely resembles the real data categories.
    \item \textbf{Diversity}: It evaluates whether the generated images are varied and not just copies of each other. This assesses the variety in the generated data.
\end{enumerate}

\subsection{Fr√©chet Inception Distance (FID)}
Another important metric we use is the Fr√©chet Inception Distance (FID. This metric compares the distribution of generated data with that of real data. The steps involved in computing this metric are:

\begin{enumerate}
    \item \textbf{Application of the Inception Network}: Both generated and real data samples are processed through the Inception network to extract feature vectors.
        \item It is assumed that the feature vectors of both the real and generated samples are distributed normally.
    \item \textbf{Calculation of the Fr√©chet Distance}: This statistical measure calculates the distance between these two Gaussian distributions. A smaller Fr√©chet distance indicates that the generated data distribution more closely resembles the real data distribution.
\end{enumerate}

\section{Time and communication size data collection}
As long as the model score, to answer our second scientific question \ref{que:b}, we collected many data during the training, such as the time required to perform a certain operation (send data, receive feedback, perform optimization step, ...). These time metrics will help use decompose every action a node perform and analyze what is the most costly action to perform in terms of time, in an other perspective this can also help finding the bottlenecks and where do we get the most idle times to find a way to optimize the distributed training procedure. Along with the time related metrics we also collected the size in MB that a node receive and send while training.
